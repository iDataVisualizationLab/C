{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ff929c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean, pdist, squareform\n",
    "from os.path import join as os_join\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from pyvis import network as net\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bfeb1f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_path = \"../data/processed/vis_dataset/similarity_combined.csv\"\n",
    "dataset_path = \"../data/processed/vis_dataset/vis_data.csv\"\n",
    "\n",
    "output_path = \"../reports/figures/ref_similarity/similarity_using_citeTo_and_citedBy.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "620ff702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conference</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>DOI</th>\n",
       "      <th>id</th>\n",
       "      <th>cite_to_list</th>\n",
       "      <th>cited_by_list</th>\n",
       "      <th>Link</th>\n",
       "      <th>FirstPage</th>\n",
       "      <th>LastPage</th>\n",
       "      <th>...</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>AuthorNames-Deduped</th>\n",
       "      <th>AuthorNames</th>\n",
       "      <th>AuthorAffiliation</th>\n",
       "      <th>InternalReferences</th>\n",
       "      <th>AuthorKeywords</th>\n",
       "      <th>AminerCitationCount_02-2020</th>\n",
       "      <th>XploreCitationCount - 2020-01</th>\n",
       "      <th>PubsCited</th>\n",
       "      <th>Award</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>SciVis</td>\n",
       "      <td>2018</td>\n",
       "      <td>Visualization of Neuronal Structures in Wide-Field Microscopy Brain Images</td>\n",
       "      <td>10.1109/TVCG.2018.2864852</td>\n",
       "      <td>1537</td>\n",
       "      <td>[745, 1397, 985, 889, 1279]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://dx.doi.org/10.1109/TVCG.2018.2864852</td>\n",
       "      <td>1018</td>\n",
       "      <td>1028</td>\n",
       "      <td>...</td>\n",
       "      <td>Wide-field microscopes are commonly used in neurobiology for experimental studies of brain samples. Available visualization tools are limited to electron, two-photon, and confocal microscopy datasets, and current volume rendering techniques do not yield effective results when used with wide-field data. We present a workflow for the visualization of neuronal structures in wide-field microscopy images of brain samples. We introduce a novel gradient-based distance transform that overcomes the out-of-focus blur caused by the inherent design of wide-field microscopes. This is followed by the extraction of the 3D structure of neurites using a multi-scale curvilinear filter and cell-bodies using a Hessian-based enhancement filter. The response from these filters is then applied as an opacity map to the raw data. Based on the visualization challenges faced by domain experts, our workflow provides multiple rendering modes to enable qualitative analysis of neuronal structures, which includes separation of cell-bodies from neurites and an intensity-based classification of the structures. Additionally, we evaluate our visualization results against both a standard image processing deconvolution technique and a confocal microscopy image of the same specimen. We show that our method is significantly faster and requires less computational resources, while producing high quality visualizations. We deploy our workflow in an immersive gigapixel facility as a paradigm for the processing and visualization of large, high-resolution, wide-field microscopy brain datasets.</td>\n",
       "      <td>Saeed Boorboor;Shreeraj Jadhav;Mala Ananth;David Talmage;Lorna Role;Arie E. Kaufman</td>\n",
       "      <td>Saeed Boorboor;Shreeraj Jadhav;Mala Ananth;David Talmage;Lorna Role;Arie Kaufman</td>\n",
       "      <td>Department of Computer ScienceStony Brook University;Department of Computer ScienceStony Brook University;Department of Neurobiology &amp; behaviorStony Brook University;Department of Neurobiology &amp; behaviorStony Brook University;Department of Neurobiology &amp; behaviorStony Brook University;Department of Computer ScienceStony Brook University</td>\n",
       "      <td>10.1109/TVCG.2014.2346312;10.1109/TVCG.2013.142;10.1109/TVCG.2012.203;10.1109/TVCG.2017.2744079;10.1109/TVCG.2009.118;10.1109/TVCG.2016.2598472</td>\n",
       "      <td>Wide-field microscopy,volume visualization,neuron visualization,neuroscience</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>VAST</td>\n",
       "      <td>2008</td>\n",
       "      <td>Using visual analytics to maintain situation awareness in astrophysics</td>\n",
       "      <td>10.1109/VAST.2008.4677353</td>\n",
       "      <td>411</td>\n",
       "      <td>[298, 336, 338, 339, 341, 342, 343, 182, 281]</td>\n",
       "      <td>[862]</td>\n",
       "      <td>http://dx.doi.org/10.1109/VAST.2008.4677353</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>We present a novel collaborative visual analytics application for cognitively overloaded users in the astrophysics domain. The system was developed for scientists needing to analyze heterogeneous, complex data under time pressure, and then make predictions and time-critical decisions rapidly and correctly under a constant influx of changing data. The Sunfall Data Taking system utilizes several novel visualization and analysis techniques to enable a team of geographically distributed domain specialists to effectively and remotely maneuver a custom-built instrument under challenging operational conditions. Sunfall Data Taking has been in use for over eighteen months by a major international astrophysics collaboration (the largest data volume supernova search currently in operation), and has substantially improved the operational efficiency of its users. We describe the system design process by an interdisciplinary team, the system architecture, and the results of an informal usability evaluation of the production system by domain experts in the context of Endsleypsilas three levels of situation awareness.</td>\n",
       "      <td>Cecilia R. Aragon;Sarah S. Poon;Gregory S. Aldering;Rollin C. Thomas;Robert Quimby</td>\n",
       "      <td>Cecilia R. Aragon;Sarah S. Poon;Gregory S. Aldering;Rollin C. Thomas;Robert Quimby</td>\n",
       "      <td>Lawrence Berkeley National Laboratory, CA 94720, USA;Space Sciences Laboratory, Berkeley, CA 94720, USA;Lawrence Berkeley National Laboratory, CA 94720, USA;Lawrence Berkeley National Laboratory, CA 94720, USA;California Institute of Technology, Pasadena, 91125, USA</td>\n",
       "      <td>10.1109/VAST.2007.4388997;10.1109/VAST.2007.4388998;10.1109/VAST.2007.4388993;10.1109/VAST.2006.261416;10.1109/VAST.2007.4388991;10.1109/VAST.2007.4388996;10.1109/VAST.2007.4388994;10.1109/VAST.2006.261434;10.1109/TVCG.2006.176;10.1109/INFVIS.2004.27</td>\n",
       "      <td>Data and knowledge visualization, scientific visualization, visual analytics, situation awareness, astrophysics</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Conference  Year  \\\n",
       "1537     SciVis  2018   \n",
       "411        VAST  2008   \n",
       "\n",
       "                                                                           Title  \\\n",
       "1537  Visualization of Neuronal Structures in Wide-Field Microscopy Brain Images   \n",
       "411       Using visual analytics to maintain situation awareness in astrophysics   \n",
       "\n",
       "                            DOI    id  \\\n",
       "1537  10.1109/TVCG.2018.2864852  1537   \n",
       "411   10.1109/VAST.2008.4677353   411   \n",
       "\n",
       "                                       cite_to_list cited_by_list  \\\n",
       "1537                    [745, 1397, 985, 889, 1279]            []   \n",
       "411   [298, 336, 338, 339, 341, 342, 343, 182, 281]         [862]   \n",
       "\n",
       "                                             Link FirstPage LastPage  ...  \\\n",
       "1537  http://dx.doi.org/10.1109/TVCG.2018.2864852      1018     1028  ...   \n",
       "411   http://dx.doi.org/10.1109/VAST.2008.4677353        27       34  ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Abstract  \\\n",
       "1537  Wide-field microscopes are commonly used in neurobiology for experimental studies of brain samples. Available visualization tools are limited to electron, two-photon, and confocal microscopy datasets, and current volume rendering techniques do not yield effective results when used with wide-field data. We present a workflow for the visualization of neuronal structures in wide-field microscopy images of brain samples. We introduce a novel gradient-based distance transform that overcomes the out-of-focus blur caused by the inherent design of wide-field microscopes. This is followed by the extraction of the 3D structure of neurites using a multi-scale curvilinear filter and cell-bodies using a Hessian-based enhancement filter. The response from these filters is then applied as an opacity map to the raw data. Based on the visualization challenges faced by domain experts, our workflow provides multiple rendering modes to enable qualitative analysis of neuronal structures, which includes separation of cell-bodies from neurites and an intensity-based classification of the structures. Additionally, we evaluate our visualization results against both a standard image processing deconvolution technique and a confocal microscopy image of the same specimen. We show that our method is significantly faster and requires less computational resources, while producing high quality visualizations. We deploy our workflow in an immersive gigapixel facility as a paradigm for the processing and visualization of large, high-resolution, wide-field microscopy brain datasets.   \n",
       "411                                                                                                                                                                                                                                                                                                                                                                                                                                                                         We present a novel collaborative visual analytics application for cognitively overloaded users in the astrophysics domain. The system was developed for scientists needing to analyze heterogeneous, complex data under time pressure, and then make predictions and time-critical decisions rapidly and correctly under a constant influx of changing data. The Sunfall Data Taking system utilizes several novel visualization and analysis techniques to enable a team of geographically distributed domain specialists to effectively and remotely maneuver a custom-built instrument under challenging operational conditions. Sunfall Data Taking has been in use for over eighteen months by a major international astrophysics collaboration (the largest data volume supernova search currently in operation), and has substantially improved the operational efficiency of its users. We describe the system design process by an interdisciplinary team, the system architecture, and the results of an informal usability evaluation of the production system by domain experts in the context of Endsleypsilas three levels of situation awareness.   \n",
       "\n",
       "                                                                      AuthorNames-Deduped  \\\n",
       "1537  Saeed Boorboor;Shreeraj Jadhav;Mala Ananth;David Talmage;Lorna Role;Arie E. Kaufman   \n",
       "411    Cecilia R. Aragon;Sarah S. Poon;Gregory S. Aldering;Rollin C. Thomas;Robert Quimby   \n",
       "\n",
       "                                                                             AuthorNames  \\\n",
       "1537    Saeed Boorboor;Shreeraj Jadhav;Mala Ananth;David Talmage;Lorna Role;Arie Kaufman   \n",
       "411   Cecilia R. Aragon;Sarah S. Poon;Gregory S. Aldering;Rollin C. Thomas;Robert Quimby   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                       AuthorAffiliation  \\\n",
       "1537  Department of Computer ScienceStony Brook University;Department of Computer ScienceStony Brook University;Department of Neurobiology & behaviorStony Brook University;Department of Neurobiology & behaviorStony Brook University;Department of Neurobiology & behaviorStony Brook University;Department of Computer ScienceStony Brook University   \n",
       "411                                                                           Lawrence Berkeley National Laboratory, CA 94720, USA;Space Sciences Laboratory, Berkeley, CA 94720, USA;Lawrence Berkeley National Laboratory, CA 94720, USA;Lawrence Berkeley National Laboratory, CA 94720, USA;California Institute of Technology, Pasadena, 91125, USA   \n",
       "\n",
       "                                                                                                                                                                                                                                              InternalReferences  \\\n",
       "1537                                                                                                             10.1109/TVCG.2014.2346312;10.1109/TVCG.2013.142;10.1109/TVCG.2012.203;10.1109/TVCG.2017.2744079;10.1109/TVCG.2009.118;10.1109/TVCG.2016.2598472   \n",
       "411   10.1109/VAST.2007.4388997;10.1109/VAST.2007.4388998;10.1109/VAST.2007.4388993;10.1109/VAST.2006.261416;10.1109/VAST.2007.4388991;10.1109/VAST.2007.4388996;10.1109/VAST.2007.4388994;10.1109/VAST.2006.261434;10.1109/TVCG.2006.176;10.1109/INFVIS.2004.27   \n",
       "\n",
       "                                                                                                       AuthorKeywords  \\\n",
       "1537                                     Wide-field microscopy,volume visualization,neuron visualization,neuroscience   \n",
       "411   Data and knowledge visualization, scientific visualization, visual analytics, situation awareness, astrophysics   \n",
       "\n",
       "     AminerCitationCount_02-2020  XploreCitationCount - 2020-01  PubsCited  \\\n",
       "1537                         NaN                            0.0       58.0   \n",
       "411                          9.0                            5.0       39.0   \n",
       "\n",
       "      Award  \n",
       "1537    NaN  \n",
       "411     NaN  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(dataset_path)\n",
    "\n",
    "dataset[\"Title\"] = dataset[\"Title\"].astype(str)\n",
    "dataset[\"AuthorNames\"] = dataset[\"AuthorNames\"].astype(str)\n",
    "\n",
    "\n",
    "dataset.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1b65fa54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<b>Paper id</b>: 0 (InfoVis)  - <a href=\"http://dx.doi.org/10.1109/INFVIS.1995.528680\" target=\"_blank\">Link</a>; <br><b>Authors: </b>: B. Spence;L. Tweedie;H. Dawkes;Hua Su; <br><b>Title</b>: Visualisation for functional design; <br><b>Abstract</b>: We present two novel visualisation tools: the Influence Explorer and the Prosection Matrix. These were specifically created to support engineering artifact design and similar tasks in which a set of parameter values must be chosen to lead to acceptable artifact performance. These tools combine two concepts. One is the interactive and virtually immediate responsive display of data in a manner conducive to the acquisition of insight. The other, involving the precalculation of samples of artifact performance, facilitates smooth exploration and optimisation leading to a design decision. The anticipated benefits of these visualisation tools are illustrated by an example taken from electronic circuit design, in which full account must be taken of the uncertainties in parameter values arising from inevitable variations in the manufacturing process.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_title_abstract = \"<b>Paper id</b>: \" + dataset[\"id\"].astype(str) + \" (\"  + dataset[\"Conference\"] + \") \" \" - \"\\\n",
    "\"<a href=\\\"\"  + dataset.Link + \"\\\" target=\\\"_blank\\\">Link</a>\" + \\\n",
    "\"; <br><b>Authors: </b>: \" + dataset[\"AuthorNames\"] + \\\n",
    "\"; <br><b>Title</b>: \" + dataset[\"Title\"] + \\\n",
    "\"; <br><b>Abstract</b>: \" + dataset[\"Abstract\"]\n",
    "\n",
    "map_id_to_label={k: v for  k,v in enumerate(id_title_abstract)}\n",
    "map_id_to_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "944e664b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>1736</th>\n",
       "      <th>1737</th>\n",
       "      <th>1738</th>\n",
       "      <th>1739</th>\n",
       "      <th>1740</th>\n",
       "      <th>1741</th>\n",
       "      <th>1742</th>\n",
       "      <th>1743</th>\n",
       "      <th>1744</th>\n",
       "      <th>1745</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>1741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>1742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>1743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>1744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>1745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1746 rows × 1747 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    0    1    2    3    4    5    6    7    8  ...  1736  1737  \\\n",
       "0        0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "1        1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "2        2  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...   0.0   0.0   \n",
       "3        3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4        4  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...   0.0   0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "1741  1741  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "1742  1742  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "1743  1743  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "1744  1744  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "1745  1745  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "      1738  1739  1740  1741  1742  1743  1744  1745  \n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "1741   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1742   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1743   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1744   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1745   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[1746 rows x 1747 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(similarity_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8e895a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>238</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>456</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>550</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60213</th>\n",
       "      <td>1611</td>\n",
       "      <td>1612</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60214</th>\n",
       "      <td>1611</td>\n",
       "      <td>1614</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60215</th>\n",
       "      <td>1611</td>\n",
       "      <td>1615</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60216</th>\n",
       "      <td>1614</td>\n",
       "      <td>1615</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60217</th>\n",
       "      <td>1614</td>\n",
       "      <td>1616</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60218 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       from    to value\n",
       "0         0   238   1.0\n",
       "1         0   244   1.0\n",
       "2         0   456   1.0\n",
       "3         0   512   1.0\n",
       "4         0   550   1.0\n",
       "...     ...   ...   ...\n",
       "60213  1611  1612   2.0\n",
       "60214  1611  1614   1.0\n",
       "60215  1611  1615   2.0\n",
       "60216  1614  1615   1.0\n",
       "60217  1614  1616   1.0\n",
       "\n",
       "[60218 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = df.values\n",
    "index_names = df.index\n",
    "col_names = df.columns\n",
    "\n",
    "#  Get indices where such threshold is crossed; avoid diagonal elems\n",
    "R,C = np.where(np.triu(arr,1)>0.0)\n",
    "\n",
    "# Arrange those in columns and put out as a dataframe\n",
    "out_arr = np.column_stack((index_names[R],col_names[C],arr[R,C]))\n",
    "df_out = pd.DataFrame(out_arr,columns=['from','to','value'])\n",
    "df_out[\"from\"] = df_out[\"from\"].astype(np.int16)\n",
    "df_out[\"to\"] = df_out[\"to\"].astype(np.int16)\n",
    "df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb725413",
   "metadata": {},
   "source": [
    "## Plot using Pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8ac041b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {\n",
    "    \"InfoVis\": \"blue\",\n",
    "    \"VAST\": \"orange\",\n",
    "    \"SciVis\": \"red\"\n",
    "}\n",
    "\n",
    "def get_node_color(node, df, color_dict):\n",
    "    conference = df[df.id == node].Conference.values[0]\n",
    "    return color_dict[conference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "afd0e383",
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = 5\n",
    "df_out_thres = df_out[df_out[\"value\"] >= thres]\n",
    "plotting_all_nodes = False\n",
    "\n",
    "file_name= output_path\n",
    "# g = net.Network(height='95%', width='99%',heading='Paper Similarity Using #BibliographicCouplings and #Co-citations')\n",
    "\n",
    "g = net.Network(height=\"700px\", width=\"100%\",heading='Paper Similarity Using #BibliographicCouplings and #Co-citations')\n",
    "g.set_edge_smooth('discrete')\n",
    "# g.set_options('{\"nodes\": {\"borderWidthSelected\": \"10\" } }')\n",
    "\n",
    "if plotting_all_nodes:\n",
    "    node_list = list(df.index.astype(np.int16))\n",
    "else:\n",
    "    node_list = list(set.union( set(df_out_thres[\"from\"]), set(df_out_thres[\"to\"]) ) )\n",
    "\n",
    "node_labels = [ map_id_to_label.get(node) for node in node_list]\n",
    "node_colors = [ get_node_color(node, dataset, color_dict) for node in node_list]\n",
    "    \n",
    "# g.add_nodes(node_list, title=node_labels, label=node_list, color=node_colors)\n",
    "\n",
    "g.add_nodes(node_list, title=node_labels, color=node_colors)\n",
    "\n",
    "\n",
    "edge_list = zip(df_out_thres[\"from\"], df_out_thres[\"to\"], df_out_thres['value'])\n",
    "g.add_edges(edge_list)    \n",
    "# g.show_buttons(filter_=[\"physics\", \"edges\"])\n",
    "# g.show_buttons()\n",
    "\n",
    "\n",
    "g.show(file_name)\n",
    "\n",
    "#  source code: https://github.com/WestHealth/pyvis/blob/523d541d04df6779dd21e5942af60b79369e8f13/pyvis/network.py#L218"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cd0bc4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "431"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.num_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c8758bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "#### Write\n",
    "with open('/Users/chaupham/minhchau/MY_WORK/C/citation_networks/models/network_plot/citation_similarity.pkl', 'wb') as f:     \n",
    "    dill.dump(g, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "262ba0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../reports/figures/ref_similarity/similarity_using_citeTo_and_citedBy.html'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf779ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!open $file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1fc4d46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!open ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa829cac",
   "metadata": {},
   "source": [
    "## Plot using Jaal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f092d4cc",
   "metadata": {},
   "source": [
    "More elegant and faster, but still in its infancy though. There's a lack of some crucial features such as \"edge thickness\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b9192c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conference</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>DOI</th>\n",
       "      <th>id</th>\n",
       "      <th>cite_to_list</th>\n",
       "      <th>cited_by_list</th>\n",
       "      <th>Link</th>\n",
       "      <th>FirstPage</th>\n",
       "      <th>LastPage</th>\n",
       "      <th>...</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>AuthorNames-Deduped</th>\n",
       "      <th>AuthorNames</th>\n",
       "      <th>AuthorAffiliation</th>\n",
       "      <th>InternalReferences</th>\n",
       "      <th>AuthorKeywords</th>\n",
       "      <th>AminerCitationCount_02-2020</th>\n",
       "      <th>XploreCitationCount - 2020-01</th>\n",
       "      <th>PubsCited</th>\n",
       "      <th>Award</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>InfoVis</td>\n",
       "      <td>1995</td>\n",
       "      <td>Visualisation for functional design</td>\n",
       "      <td>10.1109/INFVIS.1995.528680</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[990]</td>\n",
       "      <td>http://dx.doi.org/10.1109/INFVIS.1995.528680</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>We present two novel visualisation tools: the Influence Explorer and the Prosection Matrix. These were specifically created to support engineering artifact design and similar tasks in which a set of parameter values must be chosen to lead to acceptable artifact performance. These tools combine two concepts. One is the interactive and virtually immediate responsive display of data in a manner conducive to the acquisition of insight. The other, involving the precalculation of samples of artifact performance, facilitates smooth exploration and optimisation leading to a design decision. The anticipated benefits of these visualisation tools are illustrated by an example taken from electronic circuit design, in which full account must be taken of the uncertainties in parameter values arising from inevitable variations in the manufacturing process.</td>\n",
       "      <td>Robert Spence;Lisa Tweedie;Huw Dawkes;Hua Su</td>\n",
       "      <td>B. Spence;L. Tweedie;H. Dawkes;Hua Su</td>\n",
       "      <td>Dept. of Electr. Eng., Imperial Coll. of Sci., Technol. &amp; Med., London, UK;Dept. of Electr. Eng., Imperial Coll. of Sci., Technol. &amp; Med., London, UK;Dept. of Electr. Eng., Imperial Coll. of Sci., Technol. &amp; Med., London, UK;Dept. of Electr. Eng., Imperial Coll. of Sci., Technol. &amp; Med., London, UK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>InfoVis</td>\n",
       "      <td>1995</td>\n",
       "      <td>Towards a generative theory of diagram design</td>\n",
       "      <td>10.1109/INFVIS.1995.528681</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://dx.doi.org/10.1109/INFVIS.1995.528681</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>We describe the theoretical background for AVE, an automatic visualization engine for semantic networks. We have a functional notion of aesthetics and therefore understand meaningfulness as a central issue for information visualization. This implies that the diagrams should communicate the characteristics of the data as effectively as possible. In this generative theory of diagram design, we include data characterization, systematic use of graphical means of expression and the combination of graphical means of expression. After giving a brief introduction and an application scenario we discuss these aspects in detail. Finally, a process model of an automatic visualization process is sketched and directions for further research are outlined.</td>\n",
       "      <td>Klaus Reichenberger;Thomas Kamps;Gene Golovchinsky</td>\n",
       "      <td>K. Reichenberger;T. Kamps;G. Golovchinsky</td>\n",
       "      <td>GMD-Inst. for Integrated Publication &amp; Inf. Sci., Darmstadt, Germany;GMD-Inst. for Integrated Publication &amp; Inf. Sci., Darmstadt, Germany;GMD-Inst. for Integrated Publication &amp; Inf. Sci., Darmstadt, Germany</td>\n",
       "      <td>10.1109/VISUAL.1995.480815</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>InfoVis</td>\n",
       "      <td>1995</td>\n",
       "      <td>Research report: information animation applications in the capital markets</td>\n",
       "      <td>10.1109/INFVIS.1995.528682</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[32, 52]</td>\n",
       "      <td>http://dx.doi.org/10.1109/INFVIS.1995.528682</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>3D computer graphics can be extremely expressive. It is possible to display an entire securities market, like the S&amp;amp;P 500, on a single screen. With the correct approach to the visual design of the layout, these massive amounts of information can be quickly and easily comprehended by a human observer. By using motion and animated interaction, it is possible to use 3D as a reliable, accurate and precise decision-support tool. Information animation applications are particularly suited to the securities industry because that is where we find huge amounts of data, the value of which declines rapidly with time, and where critical decisions are being made on this data in very short periods of time. Information animation technology is an important new tool for the securities industry, where people need to be in the decision-making loop without suffering from information overload. Several examples are discussed including equity trading analytics, fixed income trading analytics and fixed-income risk viewing.</td>\n",
       "      <td>W. Wright</td>\n",
       "      <td>W. Wright</td>\n",
       "      <td>Visible Decisions Inc., Toronto, Ont., Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>InfoVis</td>\n",
       "      <td>1995</td>\n",
       "      <td>Research report: improving browsing in information by the automatic display layout</td>\n",
       "      <td>10.1109/INFVIS.1995.528683</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://dx.doi.org/10.1109/INFVIS.1995.528683</td>\n",
       "      <td>26</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>It is well known that graphical representations could be very helpful to browse in graph structured information. But this promising approach requires the capability of an automatic layout system because the tedious and time consuming task of a manual layout leads to a rejection of this approach by the user. In our approach, we split the task of retrieving information into two phases that are getting the orientation within the network and reading currently visited information. We present layout algorithms for both phases which have the benefit of being flexible and adaptable to individual user requests and ensure the topological consistency, i.e. the stability of the topology of the information layout during a sequence of display layouts. The results show that especially the possibility of an animation of the layout process can assist the user essentially in maintaining the orientation in the information network.</td>\n",
       "      <td>Peter Lüders;Rolf Ernst</td>\n",
       "      <td>P. Luders;R. Ernst</td>\n",
       "      <td>Tech. Univ. Braunschweig, Germany;Tech. Univ. Braunschweig, Germany</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>InfoVis</td>\n",
       "      <td>1995</td>\n",
       "      <td>SDM: malleable information graphics</td>\n",
       "      <td>10.1109/INFVIS.1995.528684</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[21, 50, 83]</td>\n",
       "      <td>http://dx.doi.org/10.1109/INFVIS.1995.528684</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>Selective dynamic manipulation (SDM) is a paradigm for interacting with objects in visualizations. Its methods offer a high degree of selectivity, in choosing object sets, in the selection of interactive techniques and the properties they affect, and in the degree to which a user action affects the visualization. Our goal is to provide a flexible set of techniques and feedback mechanisms that enable users to move objects and transform their appearance to perform a variety of information analysis tasks.</td>\n",
       "      <td>Mei C. Chuah;Steven F. Roth;Joe Mattis;John Kolojejchick</td>\n",
       "      <td>M.C. Chuah;S.F. Roth;J. Mattis;J. Kolojejchick</td>\n",
       "      <td>Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA;Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA;Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA;Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interactive techniques, visualization, direct manipulation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>VAST</td>\n",
       "      <td>2019</td>\n",
       "      <td>ICE: An Interactive Configuration Explorer for High Dimensional Categorical Parameter Spaces</td>\n",
       "      <td>10.1109/VAST47406.2019.8986923</td>\n",
       "      <td>1741</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://dx.doi.org/10.1109/VAST47406.2019.8986923</td>\n",
       "      <td>23</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>There are many applications where users seek to explore the impact of the settings of several categorical variables with respect to one dependent numerical variable. For example, a computer systems analyst might want to study how the type of file system or storage device affects system performance. A usual choice is the method of Parallel Sets designed to visualize multivariate categorical variables, However, we found that the magnitude of the parameter impacts on the numerical variable cannot be easily observed here. We also attempted a dimension reduction approach based on Multiple Correspondence Analysis but found that the SVD-generated 2D layout resulted in a loss of information. We hence propose a novel approach, the Interactive Configuration Explorer (ICE), which directly addresses the need of analysts to learn how the dependent numerical variable is affected by the parameter settings given multiple optimization objectives. No information is lost as ICE shows the complete distribution and statistics of the dependent variable in context with each categorical variable. Analysts can interactively filter the variables to optimize for certain goals such as achieving a system with maximum performance, low variance, etc. Our system was developed in tight collaboration with a group of systems performance researchers and its final effectiveness was evaluated with expert interviews, a comparative user study, and two case studies.</td>\n",
       "      <td>Anjul Tyagi;Zhen Cao;Tyler Estro;Erez Zadok;Klaus Mueller</td>\n",
       "      <td>Anjul Tyagi;Zhen Cao;Tyler Estro;Erez Zadok;Klaus Mueller</td>\n",
       "      <td>Stony Brook University,Department of Computer Science;Stony Brook University,Department of Computer Science;Stony Brook University,Department of Computer Science;Stony Brook University,Department of Computer Science;Stony Brook University,Department of Computer Science</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Clustering,Illustrative Visualization,User Interfaces,High Dimensional Data</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>VAST</td>\n",
       "      <td>2019</td>\n",
       "      <td>Influence Flowers of Academic Entities</td>\n",
       "      <td>10.1109/VAST47406.2019.8986934</td>\n",
       "      <td>1742</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://dx.doi.org/10.1109/VAST47406.2019.8986934</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>We present the Influence Flower, a new visual metaphor for the influence profile of academic entities, including people, projects, institutions, conferences, and journals. While many tools quantify influence, we aim to expose the flow of influence between entities. The Influence Flower is an ego-centric graph, with a query entity placed in the centre. The petals are styled to reflect the strength of influence to and from other entities of the same or different type. For example, one can break down the incoming and outgoing influences of a research lab by research topics. The Influence Flower uses a recent snapshot of Microsoft Academic Graph, consisting of 212 million authors, their 176 million publications, and 1.2 billion citations. An interactive web app, Influence Map, is constructed around this central metaphor for searching and curating visualisations. We also propose a visual comparison method that highlights change in influence patterns over time. We demonstrate through several case studies that the Influence Flower supports data-driven inquiries about the following: researchers' careers over time; paper(s) and projects, including those with delayed recognition; the interdisciplinary profile of a research institution; and the shifting topical trends in conferences. We also use this tool on influence data beyond academic citations, by contrasting the academic and Twitter activities of a researcher.</td>\n",
       "      <td>Minjeong Shin;Alexander Soen;Benjamin T. Readshaw;Stephen M. Blackburn;Mitchell Whitelaw;Lexing Xie</td>\n",
       "      <td>Minjeong Shin;Alexander Soen;Benjamin T. Readshaw;Stephen M. Blackburn;Mitchell Whitelaw;Lexing Xie</td>\n",
       "      <td>Australian National University;Australian National University;Australian National University;Australian National University;Australian National University;Australian National University</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Human-centered computing,Visualization,Visualisation application domains,Visual analytics,Visualization systems and tools,Empirical studies in visualization</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>VAST</td>\n",
       "      <td>2019</td>\n",
       "      <td>FDive: Learning Relevance Models Using Pattern-based Similarity Measures</td>\n",
       "      <td>10.1109/VAST47406.2019.8986940</td>\n",
       "      <td>1743</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://dx.doi.org/10.1109/VAST47406.2019.8986940</td>\n",
       "      <td>69</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>The detection of interesting patterns in large high-dimensional datasets is difficult because of their dimensionality and pattern complexity. Therefore, analysts require automated support for the extraction of relevant patterns. In this paper, we present FDive, a visual active learning system that helps to create visually explorable relevance models, assisted by learning a pattern-based similarity. We use a small set of user-provided labels to rank similarity measures, consisting of feature descriptor and distance function combinations, by their ability to distinguish relevant from irrelevant data. Based on the best-ranked similarity measure, the system calculates an interactive Self-Organizing Map-based relevance model, which classifies data according to the cluster affiliation. It also automatically prompts further relevance feedback to improve its accuracy. Uncertain areas, especially near the decision boundaries, are highlighted and can be refined by the user. We evaluate our approach by comparison to state-of-the-art feature selection techniques and demonstrate the usefulness of our approach by a case study classifying electron microscopy images of brain cells. The results show that FDive enhances both the quality and understanding of relevance models and can thus lead to new insights for brain research.</td>\n",
       "      <td>Frederik L. Dennig;Tom Polk;Zudi Lin;Tobias Schreck;Hanspeter Pfister;Michael Behrisch 0001</td>\n",
       "      <td>Frederik L. Dennig;Tom Polk;Zudi Lin;Tobias Schreck;Hanspeter Pfister;Michael Behrisch</td>\n",
       "      <td>University of Konstanz,Germany;University of Konstanz,Germany;Harvard University,USA;Graz University of Technology,Austria;Harvard University,USA;Harvard University,USA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Visual analytics,similarity measure selection,relevance feedback,active learning,self-organizing maps</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>VAST</td>\n",
       "      <td>2019</td>\n",
       "      <td>Interactive Correction of Mislabeled Training Data</td>\n",
       "      <td>10.1109/VAST47406.2019.8986943</td>\n",
       "      <td>1744</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://dx.doi.org/10.1109/VAST47406.2019.8986943</td>\n",
       "      <td>57</td>\n",
       "      <td>68</td>\n",
       "      <td>...</td>\n",
       "      <td>In this paper, we develop a visual analysis method for interactively improving the quality of labeled data, which is essential to the success of supervised and semi-supervised learning. The quality improvement is achieved through the use of user-selected trusted items. We employ a bi-level optimization model to accurately match the labels of the trusted items and to minimize the training loss. Based on this model, a scalable data correction algorithm is developed to handle tens of thousands of labeled data efficiently. The selection of the trusted items is facilitated by an incremental tSNE with improved computational efficiency and layout stability to ensure a smooth transition between different levels. We evaluated our method on real-world datasets through quantitative evaluation and case studies, and the results were generally favorable.</td>\n",
       "      <td>Shouxing Xiang;Xi Ye;Jiazhi Xia;Jing Wu;Yang Chen;Shixia Liu</td>\n",
       "      <td>Shouxing Xiang;Xi Ye;Jiazhi Xia;Jing Wu;Yang Chen;Shixia Liu</td>\n",
       "      <td>School of Software, BNRist, Tsinghua University;School of Software, BNRist, Tsinghua University;School of Computer Science and Engineering, Central South University;School of Computer Science and Informatics, Cardiff University;School of Software, BNRist, Tsinghua University;School of Software, BNRist, Tsinghua University</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Labeled data debugging,trusted item,tSNE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>VAST</td>\n",
       "      <td>2019</td>\n",
       "      <td>FAIRVIS: Visual Analytics for Discovering Intersectional Bias in Machine Learning</td>\n",
       "      <td>10.1109/VAST47406.2019.8986948</td>\n",
       "      <td>1745</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>http://dx.doi.org/10.1109/VAST47406.2019.8986948</td>\n",
       "      <td>46</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>The growing capability and accessibility of machine learning has led to its application to many real-world domains and data about people. Despite the benefits algorithmic systems may bring, models can reflect, inject, or exacerbate implicit and explicit societal biases into their outputs, disadvantaging certain demographic subgroups. Discovering which biases a machine learning model has introduced is a great challenge, due to the numerous definitions of fairness and the large number of potentially impacted subgroups. We present FAIRVIS, a mixed-initiative visual analytics system that integrates a novel subgroup discovery technique for users to audit the fairness of machine learning models. Through FAIRVIS, users can apply domain knowledge to generate and investigate known subgroups, and explore suggested and similar subgroups. FAIRVIS's coordinated views enable users to explore a high-level overview of subgroup performance and subsequently drill down into detailed investigation of specific subgroups. We show how FAIRVIS helps to discover biases in two real datasets used in predicting income and recidivism. As a visual analytics system devoted to discovering bias in machine learning, FAIRVIS demonstrates how interactive visualization may help data scientists and the general public understand and create more equitable algorithmic systems.</td>\n",
       "      <td>Ángel Alexander Cabrera;Will Epperson;Fred Hohman;Minsuk Kahng;Jamie Morgenstern;Duen Horng Chau</td>\n",
       "      <td>Ángel Alexander Cabrera;Will Epperson;Fred Hohman;Minsuk Kahng;Jamie Morgenstern;Duen Horng Chau</td>\n",
       "      <td>Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Machine learning fairness,visual analytics,intersectional bias,subgroup discovery</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1746 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Conference  Year  \\\n",
       "0       InfoVis  1995   \n",
       "1       InfoVis  1995   \n",
       "2       InfoVis  1995   \n",
       "3       InfoVis  1995   \n",
       "4       InfoVis  1995   \n",
       "...         ...   ...   \n",
       "1741       VAST  2019   \n",
       "1742       VAST  2019   \n",
       "1743       VAST  2019   \n",
       "1744       VAST  2019   \n",
       "1745       VAST  2019   \n",
       "\n",
       "                                                                                             Title  \\\n",
       "0                                                              Visualisation for functional design   \n",
       "1                                                    Towards a generative theory of diagram design   \n",
       "2                       Research report: information animation applications in the capital markets   \n",
       "3               Research report: improving browsing in information by the automatic display layout   \n",
       "4                                                              SDM: malleable information graphics   \n",
       "...                                                                                            ...   \n",
       "1741  ICE: An Interactive Configuration Explorer for High Dimensional Categorical Parameter Spaces   \n",
       "1742                                                        Influence Flowers of Academic Entities   \n",
       "1743                      FDive: Learning Relevance Models Using Pattern-based Similarity Measures   \n",
       "1744                                            Interactive Correction of Mislabeled Training Data   \n",
       "1745             FAIRVIS: Visual Analytics for Discovering Intersectional Bias in Machine Learning   \n",
       "\n",
       "                                 DOI    id cite_to_list cited_by_list  \\\n",
       "0         10.1109/INFVIS.1995.528680     0           []         [990]   \n",
       "1         10.1109/INFVIS.1995.528681     1           []            []   \n",
       "2         10.1109/INFVIS.1995.528682     2           []      [32, 52]   \n",
       "3         10.1109/INFVIS.1995.528683     3           []            []   \n",
       "4         10.1109/INFVIS.1995.528684     4           []  [21, 50, 83]   \n",
       "...                              ...   ...          ...           ...   \n",
       "1741  10.1109/VAST47406.2019.8986923  1741           []            []   \n",
       "1742  10.1109/VAST47406.2019.8986934  1742           []            []   \n",
       "1743  10.1109/VAST47406.2019.8986940  1743           []            []   \n",
       "1744  10.1109/VAST47406.2019.8986943  1744           []            []   \n",
       "1745  10.1109/VAST47406.2019.8986948  1745           []            []   \n",
       "\n",
       "                                                  Link FirstPage LastPage  \\\n",
       "0         http://dx.doi.org/10.1109/INFVIS.1995.528680         4       10   \n",
       "1         http://dx.doi.org/10.1109/INFVIS.1995.528681        11       18   \n",
       "2         http://dx.doi.org/10.1109/INFVIS.1995.528682        19       25   \n",
       "3         http://dx.doi.org/10.1109/INFVIS.1995.528683        26       33   \n",
       "4         http://dx.doi.org/10.1109/INFVIS.1995.528684        36       42   \n",
       "...                                                ...       ...      ...   \n",
       "1741  http://dx.doi.org/10.1109/VAST47406.2019.8986923        23       34   \n",
       "1742  http://dx.doi.org/10.1109/VAST47406.2019.8986934         1       10   \n",
       "1743  http://dx.doi.org/10.1109/VAST47406.2019.8986940        69       80   \n",
       "1744  http://dx.doi.org/10.1109/VAST47406.2019.8986943        57       68   \n",
       "1745  http://dx.doi.org/10.1109/VAST47406.2019.8986948        46       56   \n",
       "\n",
       "      ...  \\\n",
       "0     ...   \n",
       "1     ...   \n",
       "2     ...   \n",
       "3     ...   \n",
       "4     ...   \n",
       "...   ...   \n",
       "1741  ...   \n",
       "1742  ...   \n",
       "1743  ...   \n",
       "1744  ...   \n",
       "1745  ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Abstract  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         We present two novel visualisation tools: the Influence Explorer and the Prosection Matrix. These were specifically created to support engineering artifact design and similar tasks in which a set of parameter values must be chosen to lead to acceptable artifact performance. These tools combine two concepts. One is the interactive and virtually immediate responsive display of data in a manner conducive to the acquisition of insight. The other, involving the precalculation of samples of artifact performance, facilitates smooth exploration and optimisation leading to a design decision. The anticipated benefits of these visualisation tools are illustrated by an example taken from electronic circuit design, in which full account must be taken of the uncertainties in parameter values arising from inevitable variations in the manufacturing process.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                We describe the theoretical background for AVE, an automatic visualization engine for semantic networks. We have a functional notion of aesthetics and therefore understand meaningfulness as a central issue for information visualization. This implies that the diagrams should communicate the characteristics of the data as effectively as possible. In this generative theory of diagram design, we include data characterization, systematic use of graphical means of expression and the combination of graphical means of expression. After giving a brief introduction and an application scenario we discuss these aspects in detail. Finally, a process model of an automatic visualization process is sketched and directions for further research are outlined.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                     3D computer graphics can be extremely expressive. It is possible to display an entire securities market, like the S&amp;P 500, on a single screen. With the correct approach to the visual design of the layout, these massive amounts of information can be quickly and easily comprehended by a human observer. By using motion and animated interaction, it is possible to use 3D as a reliable, accurate and precise decision-support tool. Information animation applications are particularly suited to the securities industry because that is where we find huge amounts of data, the value of which declines rapidly with time, and where critical decisions are being made on this data in very short periods of time. Information animation technology is an important new tool for the securities industry, where people need to be in the decision-making loop without suffering from information overload. Several examples are discussed including equity trading analytics, fixed income trading analytics and fixed-income risk viewing.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 It is well known that graphical representations could be very helpful to browse in graph structured information. But this promising approach requires the capability of an automatic layout system because the tedious and time consuming task of a manual layout leads to a rejection of this approach by the user. In our approach, we split the task of retrieving information into two phases that are getting the orientation within the network and reading currently visited information. We present layout algorithms for both phases which have the benefit of being flexible and adaptable to individual user requests and ensure the topological consistency, i.e. the stability of the topology of the information layout during a sequence of display layouts. The results show that especially the possibility of an animation of the layout process can assist the user essentially in maintaining the orientation in the information network.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Selective dynamic manipulation (SDM) is a paradigm for interacting with objects in visualizations. Its methods offer a high degree of selectivity, in choosing object sets, in the selection of interactive techniques and the properties they affect, and in the degree to which a user action affects the visualization. Our goal is to provide a flexible set of techniques and feedback mechanisms that enable users to move objects and transform their appearance to perform a variety of information analysis tasks.   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ...   \n",
       "1741  There are many applications where users seek to explore the impact of the settings of several categorical variables with respect to one dependent numerical variable. For example, a computer systems analyst might want to study how the type of file system or storage device affects system performance. A usual choice is the method of Parallel Sets designed to visualize multivariate categorical variables, However, we found that the magnitude of the parameter impacts on the numerical variable cannot be easily observed here. We also attempted a dimension reduction approach based on Multiple Correspondence Analysis but found that the SVD-generated 2D layout resulted in a loss of information. We hence propose a novel approach, the Interactive Configuration Explorer (ICE), which directly addresses the need of analysts to learn how the dependent numerical variable is affected by the parameter settings given multiple optimization objectives. No information is lost as ICE shows the complete distribution and statistics of the dependent variable in context with each categorical variable. Analysts can interactively filter the variables to optimize for certain goals such as achieving a system with maximum performance, low variance, etc. Our system was developed in tight collaboration with a group of systems performance researchers and its final effectiveness was evaluated with expert interviews, a comparative user study, and two case studies.   \n",
       "1742                       We present the Influence Flower, a new visual metaphor for the influence profile of academic entities, including people, projects, institutions, conferences, and journals. While many tools quantify influence, we aim to expose the flow of influence between entities. The Influence Flower is an ego-centric graph, with a query entity placed in the centre. The petals are styled to reflect the strength of influence to and from other entities of the same or different type. For example, one can break down the incoming and outgoing influences of a research lab by research topics. The Influence Flower uses a recent snapshot of Microsoft Academic Graph, consisting of 212 million authors, their 176 million publications, and 1.2 billion citations. An interactive web app, Influence Map, is constructed around this central metaphor for searching and curating visualisations. We also propose a visual comparison method that highlights change in influence patterns over time. We demonstrate through several case studies that the Influence Flower supports data-driven inquiries about the following: researchers' careers over time; paper(s) and projects, including those with delayed recognition; the interdisciplinary profile of a research institution; and the shifting topical trends in conferences. We also use this tool on influence data beyond academic citations, by contrasting the academic and Twitter activities of a researcher.   \n",
       "1743                                                                                                                         The detection of interesting patterns in large high-dimensional datasets is difficult because of their dimensionality and pattern complexity. Therefore, analysts require automated support for the extraction of relevant patterns. In this paper, we present FDive, a visual active learning system that helps to create visually explorable relevance models, assisted by learning a pattern-based similarity. We use a small set of user-provided labels to rank similarity measures, consisting of feature descriptor and distance function combinations, by their ability to distinguish relevant from irrelevant data. Based on the best-ranked similarity measure, the system calculates an interactive Self-Organizing Map-based relevance model, which classifies data according to the cluster affiliation. It also automatically prompts further relevance feedback to improve its accuracy. Uncertain areas, especially near the decision boundaries, are highlighted and can be refined by the user. We evaluate our approach by comparison to state-of-the-art feature selection techniques and demonstrate the usefulness of our approach by a case study classifying electron microscopy images of brain cells. The results show that FDive enhances both the quality and understanding of relevance models and can thus lead to new insights for brain research.   \n",
       "1744                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       In this paper, we develop a visual analysis method for interactively improving the quality of labeled data, which is essential to the success of supervised and semi-supervised learning. The quality improvement is achieved through the use of user-selected trusted items. We employ a bi-level optimization model to accurately match the labels of the trusted items and to minimize the training loss. Based on this model, a scalable data correction algorithm is developed to handle tens of thousands of labeled data efficiently. The selection of the trusted items is facilitated by an incremental tSNE with improved computational efficiency and layout stability to ensure a smooth transition between different levels. We evaluated our method on real-world datasets through quantitative evaluation and case studies, and the results were generally favorable.   \n",
       "1745                                                                                             The growing capability and accessibility of machine learning has led to its application to many real-world domains and data about people. Despite the benefits algorithmic systems may bring, models can reflect, inject, or exacerbate implicit and explicit societal biases into their outputs, disadvantaging certain demographic subgroups. Discovering which biases a machine learning model has introduced is a great challenge, due to the numerous definitions of fairness and the large number of potentially impacted subgroups. We present FAIRVIS, a mixed-initiative visual analytics system that integrates a novel subgroup discovery technique for users to audit the fairness of machine learning models. Through FAIRVIS, users can apply domain knowledge to generate and investigate known subgroups, and explore suggested and similar subgroups. FAIRVIS's coordinated views enable users to explore a high-level overview of subgroup performance and subsequently drill down into detailed investigation of specific subgroups. We show how FAIRVIS helps to discover biases in two real datasets used in predicting income and recidivism. As a visual analytics system devoted to discovering bias in machine learning, FAIRVIS demonstrates how interactive visualization may help data scientists and the general public understand and create more equitable algorithmic systems.   \n",
       "\n",
       "                                                                                      AuthorNames-Deduped  \\\n",
       "0                                                            Robert Spence;Lisa Tweedie;Huw Dawkes;Hua Su   \n",
       "1                                                      Klaus Reichenberger;Thomas Kamps;Gene Golovchinsky   \n",
       "2                                                                                               W. Wright   \n",
       "3                                                                                 Peter Lüders;Rolf Ernst   \n",
       "4                                                Mei C. Chuah;Steven F. Roth;Joe Mattis;John Kolojejchick   \n",
       "...                                                                                                   ...   \n",
       "1741                                            Anjul Tyagi;Zhen Cao;Tyler Estro;Erez Zadok;Klaus Mueller   \n",
       "1742  Minjeong Shin;Alexander Soen;Benjamin T. Readshaw;Stephen M. Blackburn;Mitchell Whitelaw;Lexing Xie   \n",
       "1743          Frederik L. Dennig;Tom Polk;Zudi Lin;Tobias Schreck;Hanspeter Pfister;Michael Behrisch 0001   \n",
       "1744                                         Shouxing Xiang;Xi Ye;Jiazhi Xia;Jing Wu;Yang Chen;Shixia Liu   \n",
       "1745     Ángel Alexander Cabrera;Will Epperson;Fred Hohman;Minsuk Kahng;Jamie Morgenstern;Duen Horng Chau   \n",
       "\n",
       "                                                                                              AuthorNames  \\\n",
       "0                                                                   B. Spence;L. Tweedie;H. Dawkes;Hua Su   \n",
       "1                                                               K. Reichenberger;T. Kamps;G. Golovchinsky   \n",
       "2                                                                                               W. Wright   \n",
       "3                                                                                      P. Luders;R. Ernst   \n",
       "4                                                          M.C. Chuah;S.F. Roth;J. Mattis;J. Kolojejchick   \n",
       "...                                                                                                   ...   \n",
       "1741                                            Anjul Tyagi;Zhen Cao;Tyler Estro;Erez Zadok;Klaus Mueller   \n",
       "1742  Minjeong Shin;Alexander Soen;Benjamin T. Readshaw;Stephen M. Blackburn;Mitchell Whitelaw;Lexing Xie   \n",
       "1743               Frederik L. Dennig;Tom Polk;Zudi Lin;Tobias Schreck;Hanspeter Pfister;Michael Behrisch   \n",
       "1744                                         Shouxing Xiang;Xi Ye;Jiazhi Xia;Jing Wu;Yang Chen;Shixia Liu   \n",
       "1745     Ángel Alexander Cabrera;Will Epperson;Fred Hohman;Minsuk Kahng;Jamie Morgenstern;Duen Horng Chau   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                        AuthorAffiliation  \\\n",
       "0                             Dept. of Electr. Eng., Imperial Coll. of Sci., Technol. & Med., London, UK;Dept. of Electr. Eng., Imperial Coll. of Sci., Technol. & Med., London, UK;Dept. of Electr. Eng., Imperial Coll. of Sci., Technol. & Med., London, UK;Dept. of Electr. Eng., Imperial Coll. of Sci., Technol. & Med., London, UK   \n",
       "1                                                                                                                          GMD-Inst. for Integrated Publication & Inf. Sci., Darmstadt, Germany;GMD-Inst. for Integrated Publication & Inf. Sci., Darmstadt, Germany;GMD-Inst. for Integrated Publication & Inf. Sci., Darmstadt, Germany   \n",
       "2                                                                                                                                                                                                                                                                                           Visible Decisions Inc., Toronto, Ont., Canada   \n",
       "3                                                                                                                                                                                                                                                                     Tech. Univ. Braunschweig, Germany;Tech. Univ. Braunschweig, Germany   \n",
       "4                                                                     Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA;Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA;Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA;Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA   \n",
       "...                                                                                                                                                                                                                                                                                                                                   ...   \n",
       "1741                                                        Stony Brook University,Department of Computer Science;Stony Brook University,Department of Computer Science;Stony Brook University,Department of Computer Science;Stony Brook University,Department of Computer Science;Stony Brook University,Department of Computer Science   \n",
       "1742                                                                                                                                            Australian National University;Australian National University;Australian National University;Australian National University;Australian National University;Australian National University   \n",
       "1743                                                                                                                                                             University of Konstanz,Germany;University of Konstanz,Germany;Harvard University,USA;Graz University of Technology,Austria;Harvard University,USA;Harvard University,USA   \n",
       "1744  School of Software, BNRist, Tsinghua University;School of Software, BNRist, Tsinghua University;School of Computer Science and Engineering, Central South University;School of Computer Science and Informatics, Cardiff University;School of Software, BNRist, Tsinghua University;School of Software, BNRist, Tsinghua University   \n",
       "1745                                                                                                                                      Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology;Georgia Institute of Technology   \n",
       "\n",
       "              InternalReferences  \\\n",
       "0                            NaN   \n",
       "1     10.1109/VISUAL.1995.480815   \n",
       "2                            NaN   \n",
       "3                            NaN   \n",
       "4                            NaN   \n",
       "...                          ...   \n",
       "1741                         NaN   \n",
       "1742                         NaN   \n",
       "1743                         NaN   \n",
       "1744                         NaN   \n",
       "1745                         NaN   \n",
       "\n",
       "                                                                                                                                                    AuthorKeywords  \\\n",
       "0                                                                                                                                                              NaN   \n",
       "1                                                                                                                                                              NaN   \n",
       "2                                                                                                                                                              NaN   \n",
       "3                                                                                                                                                              NaN   \n",
       "4                                                                                                       Interactive techniques, visualization, direct manipulation   \n",
       "...                                                                                                                                                            ...   \n",
       "1741                                                                              Data Clustering,Illustrative Visualization,User Interfaces,High Dimensional Data   \n",
       "1742  Human-centered computing,Visualization,Visualisation application domains,Visual analytics,Visualization systems and tools,Empirical studies in visualization   \n",
       "1743                                                         Visual analytics,similarity measure selection,relevance feedback,active learning,self-organizing maps   \n",
       "1744                                                                                                                      Labeled data debugging,trusted item,tSNE   \n",
       "1745                                                                             Machine learning fairness,visual analytics,intersectional bias,subgroup discovery   \n",
       "\n",
       "     AminerCitationCount_02-2020  XploreCitationCount - 2020-01  PubsCited  \\\n",
       "0                            NaN                           12.0       10.0   \n",
       "1                           12.0                            4.0       18.0   \n",
       "2                           24.0                            7.0       10.0   \n",
       "3                            5.0                            2.0       15.0   \n",
       "4                            NaN                            5.0       16.0   \n",
       "...                          ...                            ...        ...   \n",
       "1741                         0.0                            0.0        NaN   \n",
       "1742                         0.0                            0.0        NaN   \n",
       "1743                         0.0                            0.0        NaN   \n",
       "1744                         0.0                            0.0        NaN   \n",
       "1745                         0.0                            0.0        NaN   \n",
       "\n",
       "      Award  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  \n",
       "...     ...  \n",
       "1741    NaN  \n",
       "1742    NaN  \n",
       "1743    NaN  \n",
       "1744    NaN  \n",
       "1745    NaN  \n",
       "\n",
       "[1746 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865c62b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaacf58b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc5050b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaupham/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/chaupham/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1746, 4)\n",
      "(294, 4)\n",
      "Parsing the data...Done\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaupham/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/chaupham/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:692: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value, self.name)\n",
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [13/Apr/2021 00:26:52] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:26:53] \"\u001b[37mGET /_dash-dependencies HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:26:53] \"\u001b[37mGET /_dash-layout HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:26:53] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:26:53] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No trigger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [13/Apr/2021 00:26:54] \"\u001b[37mGET /_favicon.ico?v=1.19.0 HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:26:57] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:01] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:19] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:20] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:27] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:27] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:28] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:28] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:28] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:28] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:28] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:28] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:29] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:29] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:29] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:29] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:29] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:29] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:29] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:29] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:29] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:29] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:29] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:30] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:30] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:30] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:30] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:30] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:30] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:30] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:30] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:30] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:30] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:30] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:31] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:31] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:31] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:31] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:31] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:33] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:34] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:37] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:38] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Apr/2021 00:27:39] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from jaal import Jaal\n",
    "from jaal.datasets import load_got\n",
    "\n",
    "\n",
    "thres = 6\n",
    "plotting_all_nodes = False\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "df_out_thres = df_out[df_out[\"value\"] >= thres]\n",
    "edges = df_out_thres\n",
    "\n",
    "(dataset)\n",
    "# edges.loc[:, 'label'] = edges.loc[:, 'value'].astype(int).astype(str)\n",
    "\n",
    "edges[\"from\"] = edges[\"from\"].map(lambda node_id: \" - \".join(dataset[dataset[\"id\"] == node_id ][[\"Title\", \"AuthorNames\"]].values[0]))\n",
    "edges[\"to\"] = edges[\"to\"].map(lambda node_id: \" - \".join(dataset[dataset[\"id\"] == node_id ][[\"Title\", \"AuthorNames\"]].values[0])) \n",
    "\n",
    "\n",
    "set_thres_nodes = set.union( set(df_out_thres[\"from\"]), set(df_out_thres[\"to\"]) )\n",
    "nodes = pd.DataFrame({\"id\": df.index})\n",
    "nodes[\"having_edge\"] = nodes[\"id\"].map(lambda x: x in set_thres_nodes).astype(str)\n",
    "nodes[\"conference\"] = nodes[\"id\"].map(lambda node_id: dataset[dataset[\"id\"] == node_id ][\"Conference\"].values[0])\n",
    "nodes[\"Title\"] = nodes[\"id\"].map(lambda node_id: \" - \".join(dataset[dataset[\"id\"] == node_id ][[\"Title\", \"AuthorNames\"]].values[0])) \n",
    "nodes[\"id\"] = nodes[\"Title\"]\n",
    "if plotting_all_nodes:\n",
    "    pass\n",
    "else:\n",
    "    print(nodes.shape)\n",
    "    node_list = set.union( set(df_out_thres[\"from\"]), set(df_out_thres[\"to\"]) ) \n",
    "    nodes = nodes[nodes[\"id\"].isin(node_list)]\n",
    "    print(nodes.shape)\n",
    "\n",
    "nodes.to_csv(\"../data/interim/jaal_data/nodes_2.csv\", index=False)\n",
    "edges.to_csv(\"../data/interim/jaal_data/edges_2.csv\", index=False)\n",
    "\n",
    "port=8050\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        Jaal(edges, nodes).plot(port=port)\n",
    "    except:\n",
    "        port+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1449279",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges[\"value\"] = edges[\"value\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa04b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.nlargest(10,\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba00db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62755dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[nodes.id==1606].Title.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7585ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges[(edges[\"to\"] == 755) & (edges[\"from\"]==456)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbae253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
